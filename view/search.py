"""
Author: ë¬¸ì§€ì˜
Date: 2025-10-22
Description: íì°¨ì¥ ìœ„ì¹˜ ê²€ìƒ‰ í™”ë©´
"""
import streamlit.components.v1 as components 
import streamlit as st
import pandas as pd
import urllib.parse
import math, requests
import requests
import json
from pathlib import Path

# --------------------
# ì„¤ì •(ìƒìˆ˜)
# --------------------
API_BASE_URL = "http://127.0.0.1:5000"
API_SCRAPYARD = f"{API_BASE_URL}/scrapyards"
API_FAQ_URL = f"{API_BASE_URL}/faqs"

st.markdown("""

            
            
<style>
/* íŒŒë€ìƒ‰ ê²€ìƒ‰ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì •ì˜ */
.stButton>button {
    color: white;
    background-color: #1158e0; 
    border-radius: 5px;
    padding: 8px 16px;
    font-weight: bold;
    border: 1px solid #1158e0;
    /* ë“œë¡­ë‹¤ìš´ ë°•ìŠ¤ì™€ ìˆ˜ì§ ìœ„ì¹˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ë§ˆì§„ ì¡°ì • */
    margin-top: 10px; 
}
            
/* st.info ìœ„ì ¯ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ ë° íŒ¨ë”© ì¡°ì • */
div[data-testid="stAlert"] div[role="alert"] {
    text-align: center; 
    padding-top: 15px;
    padding-bottom: 15px;
}

/* DataFrame í…Œì´ë¸” ë„ˆë¹„ë¥¼ 100%ë¡œ ì„¤ì • */
.dataframe {
    width: 100%;
}
/* st.info ìœ„ì ¯ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ ë° íŒ¨ë”© ì¡°ì • */
div[data-testid="stAlert"] div[role="alert"] {
    text-align: center; 
    padding-top: 15px;
    padding-bottom: 15px;
}
/* ìˆ˜ë™ í…Œì´ë¸” êµ¬ë¶„ì„  ìŠ¤íƒ€ì¼ */
.row-divider {
    margin: 0px 0;
    border: 0.5px solid #eee;
}
.header-divider {
    margin: 0px 0 10px 0;
    border: 1px solid #ddd;
}
/* íŠ¹ì • í´ë˜ìŠ¤ ë‚´ë¶€ ìš”ì†Œ ì¤‘ì•™ ì •ë ¬ /
.stVerticalBlock .st-emotion-cache-wfksaw.e196pkbe2 {
    display: flex;
    flex-direction: column;
    align-items: center;  / ê°€ë¡œ ë°©í–¥ ì¤‘ì•™ ì •ë ¬ /
    justify-content: center;  / ì„¸ë¡œ ë°©í–¥ ì¤‘ì•™ ì •ë ¬ /
    text-align: center;  / í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ */
}
</style>
""", unsafe_allow_html=True)
API_SCRAPYARD = "http://127.0.0.1:5000/scrapyards"
# --------------------
# API í˜¸ì¶œ ìœ í‹¸
# --------------------
@st.cache_data
def check_api_base(url: str = API_BASE_URL, timeout: int = 3) -> bool:
    try:
        resp = requests.get(url, timeout=timeout)
        resp.raise_for_status()
        return True
    except requests.exceptions.RequestException:
        return False

@st.cache_data
def load_faq_from_api(url: str = API_FAQ_URL, timeout: int = 5):
    try:
        resp = requests.get(url, timeout=timeout)
        resp.raise_for_status()
        return resp.json()
    except requests.exceptions.RequestException:
        return []

def normalize_faq_list(data):
    if not isinstance(data, list):
        if isinstance(data, dict) and "data" in data and isinstance(data["data"], list):
            data = data["data"]
        else:
            return []
    normalized = []
    for item in data:
        if not isinstance(item, dict):
            continue
        q = item.get("Q") or item.get("QUESTION") or item.get("question")
        a = item.get("A") or item.get("ANSWER") or item.get("answer")
        src = item.get("ì¶œì²˜") or item.get("source") or item.get("SOURCE") or ""
        if q and a:
            normalized.append({"Q": str(q).strip(), "A": str(a).strip(), "ì¶œì²˜": str(src).strip()})
    return normalized

# --------------------
# 1. ì¹´ì¹´ì˜¤ë§µ URL ìƒì„± í•¨ìˆ˜ (ìƒë‹¨ì— ì •ì˜)
# --------------------
def create_kakaomap_url(address):
    """ì£¼ì†Œë¥¼ ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ URLë¡œ ì¸ì½”ë”©í•˜ì—¬ ìƒˆ ì°½ìœ¼ë¡œ ì—¬ëŠ” URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    base_url = "https://map.kakao.com/"
    encoded_address = urllib.parse.quote(address)
    return f"{base_url}?q={encoded_address}"

def get_kakao_map_iframe_url(address):
    """ì£¼ì†Œë¥¼ ì¹´ì¹´ì˜¤ë§µ iframe ì„ë² ë”©ìš© URLë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤. (ê²€ìƒ‰ì°½ ìˆ¨ê¹€)"""
    # ì¹´ì¹´ì˜¤ë§µ ê°œë°œì APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  iframe ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤.
    encoded_address = urllib.parse.quote(address)
    # ë§µ ì£¼ì†Œ + ê²€ìƒ‰ì–´ë¥¼ iframeì— ë°”ë¡œ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.
    return f"https://map.kakao.com/?q={encoded_address}&map_type=TYPE_MAP&src=internal"

# --------------------
# ì§€ì—­ë³„ ì„¸ë¶€ êµ¬/ì‹œ ë°ì´í„° ì •ì˜ (ì „ì—­ ë³€ìˆ˜ ìœ„ì¹˜. ì„ì˜ë¡œ ì§€ì •.)
# --------------------
SEOUL_DISTRICTS = ['ê°•ë‚¨êµ¬', 'ì„±ë¶êµ¬', 'ì„±ë™êµ¬', 'ì˜ë“±í¬êµ¬', 'ì „ì²´']
GYEONGGI_CITIES = ['ìˆ˜ì›ì‹œ', 'ì„±ë‚¨ì‹œ', 'ìš©ì¸ì‹œ', 'í™”ì„±ì‹œ', 'ì „ì²´']
INCHEON_DISTRICTS = ['ì—°ìˆ˜êµ¬', 'ë‚¨ë™êµ¬', 'ë¶€í‰êµ¬', 'ì„œêµ¬', 'ì „ì²´']

REGION_DETAILS = {
    'ì„œìš¸': SEOUL_DISTRICTS,
    'ê²½ê¸°': GYEONGGI_CITIES,
    'ì¸ì²œ': INCHEON_DISTRICTS,
    'ì „ì²´': ['ì „ì²´']
}

# --------------------
# 3. Mock Data (ë°±ì—”ë“œ ëŒ€ì²´ í•¨ìˆ˜. ì„ì˜ë¡œ ì§€ì •)
# --------------------
def get_scrapyard_list_with_address(selected_area, selected_district):
    """
    Flask APIë¡œ íì°¨ì¥ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜
    """
    try:
        # Streamlit â†’ Flask ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬
        params = {}
        if selected_area not in ("", "ì „ì²´"):
            # ë°±ì—”ë“œì—ì„œëŠ” 'REGION_CODE'ë¥¼ ì“°ê¸° ë•Œë¬¸ì— ë³€í™˜ í•„ìš” (ì„œìš¸=02, ê²½ê¸°=01, ì¸ì²œ=11)
            region_map = {"ì„œìš¸": "02", "ê²½ê¸°": "01", "ì¸ì²œ": "11"}
            params["region"] = region_map.get(selected_area)
        if selected_district not in ("", "ì „ì²´"):
            params["subregion"] = selected_district

        # Flaskë¡œ GET ìš”ì²­
        response = requests.get(API_SCRAPYARD, params=params, timeout=5)
        response.raise_for_status()

        data = response.json()
        if not data:
            st.warning("ì¡°ê±´ì— ë§ëŠ” íì°¨ì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # JSON â†’ DataFrame
        df = pd.DataFrame(data)

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ (UI í‘œì‹œì— ë§ê²Œ)
        df.rename(columns={
            "SY_NAME": "ì—…ì²´ëª…",
            "ADDRESS": "ì£¼ì†Œ",
            "CONTACT_NUMBER": "ì—°ë½ì²˜",
            "REGION_CODE": "ì§€ì—­ì½”ë“œ",
            "SUBREGION_NAME": "ì„¸ë¶€ì§€ì—­"
        }, inplace=True)

        return df

    except requests.exceptions.RequestException as e:
        st.error(f"ğŸš¨ Flask ì„œë²„ í†µì‹  ì˜¤ë¥˜: {e}")
        return pd.DataFrame()


# ----------------------------------------------------
# ğŸŒŸ ì½œë°± í•¨ìˆ˜: 'ê²€ìƒ‰' ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
# ----------------------------------------------------
def perform_search_and_reset():
    """ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  í˜ì´ì§€ ë° ì§€ë„ ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    # ë“œë¡­ë‹¤ìš´ ìœ„ì ¯ì˜ í˜„ì¬ ê°’(ì„¸ì…˜ ìƒíƒœì— ì €ì¥ë˜ì–´ ìˆìŒ)ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰
    selected_area = st.session_state.area_select # key="area_select"ì˜ ê°’
    selected_district = st.session_state.district_select # key="district_select"ì˜ ê°’
    
    # 1. í˜ì´ì§€ ì´ˆê¸°í™”
    st.session_state.current_page = 1
    st.session_state.map_info = {'address': None, 'url': None}
    
    # 2. DB í•¨ìˆ˜ í˜¸ì¶œ ë° ê²°ê³¼ ì €ì¥
    result_df = get_scrapyard_list_with_address(selected_area, selected_district)
    st.session_state.last_search_df = result_df



# 1. í˜ì´ì§€ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
st.set_page_config(
    page_title="ìˆ˜ë„ê¶Œ íì°¨ì¥ ì¡°íšŒ ë° FAQ ì‹œìŠ¤í…œ",
    page_icon="ğŸš™",
    layout="wide",
    initial_sidebar_state="expanded"
)


# 2. ì‚¬ì´ë“œë°” ë©”ë‰´ êµ¬í˜„ (key ì¶”ê°€ë¡œ DuplicateElementId ì˜¤ë¥˜ í•´ê²°)
st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ë©”ë‰´")
menu = st.sidebar.radio(" ",
    ('íì°¨ì¥ ì¡°íšŒ', 'FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ'),
    key='sidebar_menu' # <-- key ì¶”ê°€
)


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í˜ì´ì§€ë„¤ì´ì…˜ ë° ì§€ë„)
if 'current_page' not in st.session_state:
    st.session_state.current_page = 1
if 'last_search_df' not in st.session_state:
    st.session_state.last_search_df = pd.DataFrame()
# ì§€ë„ ì„ë² ë“œ ì •ë³´ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì¶”ê°€
if 'map_info' not in st.session_state:
    st.session_state.map_info = {'address': None, 'url': None}
    
# ê²€ìƒ‰ ë“œë¡­ë‹¤ìš´ ì„ íƒê°’ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” 
if 'area_select' not in st.session_state:
    st.session_state.area_select = 'ì „ì²´'
if 'district_select' not in st.session_state:
    st.session_state.district_select = 'ì „ì²´'


# --------------------
# 5. íì°¨ì¥ ì¡°íšŒ í•¨ìˆ˜ 
# --------------------
def show_scrapyard_finder():
    """ íì°¨ì¥ ì¡°íšŒ í˜ì´ì§€ (ì§€ë„ ì„ë² ë“œ ê¸°ëŠ¥ í†µí•©) """
    st.header ("ğŸš™ ìˆ˜ë„ê¶Œ íì°¨ì¥ ì¡°íšŒ")
    
    # ê¸°ì¡´ ì½”ë“œì—ì„œ ë°œê²¬ëœ ë¶ˆí•„ìš”í•œ HTML ë§ˆí¬ë‹¤ìš´ ì œê±° (st.writeë¡œ ëŒ€ì²´)
    st.write("ì›í•˜ëŠ” ì§€ì—­ê³¼ ì„¸ë¶€ ì§€ì—­ì„ ì„ íƒí•œ í›„ ê²€ìƒ‰í•˜ì„¸ìš”.")

    # col3ì˜ ë¹„ìœ¨ì„ 0.4ë¡œ ìœ ì§€í•˜ë©° ë²„íŠ¼ì´ í•œ ì¤„ë¡œ ë‚˜ì˜¤ë„ë¡ í•©ë‹ˆë‹¤.
    col1, col2, col3 = st.columns([1, 1, 0.4])

    # ê²€ìƒ‰ ì¡°ê±´ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (keyë¥¼ ì‚¬ìš©í•´ st.session_stateì— ìë™ ì €ì¥ë¨)
    with col1:
        st.selectbox(
            "ì§€ì—­ë³„ ê²€ìƒ‰ (ì‹œ/ë„)",
            ['ì „ì²´', 'ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ'],
            index = ['ì „ì²´', 'ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ'].index(st.session_state.area_select),
            key="area_select" # ì´ keyë¡œ st.session_state.area_selectì— ê°’ì´ ì €ì¥ë¨
        )
    
    with col2:
        # st.session_state.area_selectì˜ ê°’ì„ ì‚¬ìš©
        detail_options = REGION_DETAILS.get(st.session_state.area_select, ['ì „ì²´'])
        st.selectbox(
            f"'{st.session_state.area_select}'ì˜ ì„¸ë¶€ ì§€ì—­ ê²€ìƒ‰ (êµ¬/ì‹œ)",
            detail_options,
            index=detail_options.index(st.session_state.district_select) if st.session_state.district_select in detail_options else detail_options.index('ì „ì²´'),
            key="district_select" # ì´ keyë¡œ st.session_state.district_districtì— ê°’ì´ ì €ì¥ë¨
        )

    # ê²€ìƒ‰ ë²„íŠ¼ (ì½œë°± í•¨ìˆ˜ ì‚¬ìš©)
    with col3:
        st.markdown('<div class="blue-button">', unsafe_allow_html=True)
        # 'ê²€ìƒ‰' ë²„íŠ¼ í´ë¦­ ì‹œ perform_search_and_reset í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ê³  st.rerun() ë¨
        st.button("ê²€ìƒ‰", on_click=perform_search_and_reset, key="search_button_widget", use_container_width=True) 
        st.markdown('</div>', unsafe_allow_html=True)    
                        
        

# -----------------------------------------------------------------
# í˜ì´ì§• ë° ê²°ê³¼ ì¶œë ¥ ì˜ì—­
# -----------------------------------------------------------------
    
    if not st.session_state.last_search_df.empty:
        
        result_df = st.session_state.last_search_df
        total_rows = len(result_df)
        page_size = 5
        total_pages = math.ceil(total_rows / page_size)
        current_page = st.session_state.current_page

        st.subheader(f"ğŸ” ì¡°íšŒ ê²°ê³¼ (**{total_rows}**ê±´)")

        # í˜„ì¬ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ìŠ¬ë¼ì´ì‹±
        start_row = (current_page - 1) * page_size
        end_row = start_row + page_size
        paginated_df = result_df.iloc[start_row:end_row].copy()


        # ê²°ê³¼ í…Œì´ë¸” í—¤ë” ìˆ˜ë™ ìƒì„±
        # (ì´ì „ ìš”ì²­ì— ë”°ë¥¸ ë²„íŠ¼ ë„ˆë¹„ í•´ê²°ì„ ìœ„í•´ 4ë²ˆì§¸ ì»¬ëŸ¼ ë¹„ìœ¨ ì¡°ì •ëœ ê²ƒ ìœ ì§€)
        header_cols = st.columns([2.5, 2.5, 2.0, 2.0]) 
        header_cols[0].markdown('**ì—…ì²´ëª…**')
        header_cols[1].markdown('**ì£¼ì†Œ**')
        header_cols[2].markdown('**ì—°ë½ì²˜**')
        header_cols[3].markdown('**ì§€ë„**')

        st.markdown('<hr class="header-divider"/>', unsafe_allow_html=True) # í—¤ë”ì™€ ë‚´ìš© êµ¬ë¶„ì„ 

        
        # ê²°ê³¼ í…Œì´ë¸” ë‚´ìš© ìˆ˜ë™ ìƒì„± (ë²„íŠ¼ í†µí•©)
        for index, row in paginated_df.iterrows():
            # (ì´ì „ ìš”ì²­ì— ë”°ë¥¸ ë²„íŠ¼ ë„ˆë¹„ í•´ê²°ì„ ìœ„í•´ 4ë²ˆì§¸ ì»¬ëŸ¼ ë¹„ìœ¨ ì¡°ì •ëœ ê²ƒ ìœ ì§€)
            row_cols = st.columns([2.5, 3.5, 1.5, 2.0]) # ë„ˆë¹„ ë¹„ìœ¨ì€ í—¤ë”ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€
            
            # ì—…ì²´ëª… (ë§í¬ ëŒ€ì‹  í…ìŠ¤íŠ¸ ì¶œë ¥)
            row_cols[0].markdown(f"**{row['ì—…ì²´ëª…']}**", unsafe_allow_html=True)
            
            # ì£¼ì†Œ
            row_cols[1].markdown(row['ì£¼ì†Œ'])
            
            # ì—°ë½ì²˜
            row_cols[2].markdown(row['ì—°ë½ì²˜'])

            # 'ì§€ë„ ë³´ê¸°' ë²„íŠ¼ (ë²„íŠ¼ í´ë¦­ ì‹œ ì§€ë„ ì„ë² ë“œ)
            with row_cols[3]:
                if st.button("ğŸ—ºï¸ ì§€ë„ ë³´ê¸°", key=f"mapbtn{row['ID']}", use_container_width=True):
                    st.session_state.map_info['address'] = row['ì£¼ì†Œ']
                    st.session_state.map_info['url'] = get_kakao_map_iframe_url(row['ì£¼ì†Œ'])
                    st.rerun()
            
            # ê° í–‰ì˜ ì¤‘ê°„ êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown('<hr class="row-divider"/>', unsafe_allow_html=True)
        
        # 3. í˜ì´ì§€ ì´ë™ ë²„íŠ¼
        st.markdown("---")
        col_prev, col_page_info, col_next = st.columns([1, 2, 1])
        
        with col_prev:
            if current_page > 1:
                # ì´ì „ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œ ì„¸ì…˜ ìƒíƒœ current_pageë§Œ ë³€ê²½
                if st.button("â¬…ï¸ ì´ì „ í˜ì´ì§€"):
                    st.session_state.current_page -= 1
                    st.rerun()

        with col_page_info:
            st.markdown(f"<div style='text-align:center;'>í˜ì´ì§€ {current_page} / {total_pages}</div>", unsafe_allow_html=True)
            
        with col_next:
            if current_page < total_pages:
                # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œ ì„¸ì…˜ ìƒíƒœ current_pageë§Œ ë³€ê²½
                if st.button("ë‹¤ìŒ í˜ì´ì§€ â¡ï¸"):
                    st.session_state.current_page += 1
                    st.rerun()

    else:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ (ì´ˆê¸° ìƒíƒœ í¬í•¨)
        st.info("ê²€ìƒ‰ ì¡°ê±´ì„ ì„ íƒí•˜ê³  'ê²€ìƒ‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


    # ğŸŒŸ 5-3. ì§€ë„ ì„ë² ë“œ ì˜ì—­ (í•¨ìˆ˜ ë§ˆì§€ë§‰ì— ìœ„ì¹˜) ------------------
    if st.session_state.map_info['address']:
        import streamlit.components.v1 as components # í•¨ìˆ˜ ë‚´ì—ì„œ ë‹¤ì‹œ import
        st.markdown("---")
        st.subheader(f"ğŸ—ºï¸ ìœ„ì¹˜ í™•ì¸: {st.session_state.map_info['address']}")

        map_url = st.session_state.map_info['url']

        # ì¹´ì¹´ì˜¤ ì§€ë„ iframe ì„ë² ë“œ
        components.html(
            f"""
            <iframe 
                width="100%" 
                height="500" 
                frameborder="0" 
                scrolling="no" 
                marginwidth="0" 
                marginheight="0" 
                src="{map_url}"
            >
            </iframe>
            """,
            height=520, # iframe ë†’ì´
        )


# ----------------------------------------------------
# 6. FAQ ì‹œìŠ¤í…œ í•¨ìˆ˜ (ê²€ìƒ‰ ê¸°ëŠ¥ ì œê±°, expanderë¡œ ëª©ë¡ í‘œì‹œ)
# ----------------------------------------------------
def show_faq_system():
    st.header("â“ íì°¨ ê´€ë ¨ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)")
    st.write("ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ëª©ë¡ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ í´ë¦­í•˜ì‹œë©´ ë‹µë³€ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ì„œë²„ ì—°ê²° ì—¬ë¶€ í™•ì¸
    if not check_api_base():
        st.error(f"ì„œë²„({API_BASE_URL})ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    raw = load_faq_from_api()
    if not raw:
        st.info("FAQ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (API ì‘ë‹µ ì—†ìŒ)")
        return

    faq_list = normalize_faq_list(raw)
    if not faq_list:
        st.warning("API ì‘ë‹µì„ ë°›ì•˜ìœ¼ë‚˜ ìœ íš¨í•œ FAQ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(faq_list)
    for i, row in df.iterrows():
        q = row.get("Q", "")
        a = row.get("A", "")
        src = row.get("ì¶œì²˜", "")
        with st.expander(f"Q{i+1}. {q}"):
            st.markdown(a)
            if src:
                st.caption(f"ì¶œì²˜: {src}")

# --------------------
# ë©”ì¸ ë¼ìš°íŒ…
# --------------------
if menu == 'íì°¨ì¥ ì¡°íšŒ':
    show_scrapyard_finder()
elif menu == 'FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ':
    show_faq_system()